














#Importing necessary libraries
import numpy as np 
import matplotlib.pyplot as plt
import pandas as pd #To read and organize files
import scipy.constants as cte #To get physical constants
import scipy.optimize as opt #To get the right parameters
import scipy.stats as st #To get statistic coefficients (Pearson, Spearman, etc) 
import scipy.interpolate as interp #To interpolate data





PATH = "1D-data/"
filename = "CapeGrim_CO2_data_download.csv"


# Inspecting the data with vim, we can see that there are 24 rows as headers.
#df = pd.read_csv(PATH+filename, skiprows=24)
#df



# Defining the input-output function
def io_data(filename):
    """
    This is an I/O function that opens a file with data
    and return data arrays.
    Input: filename (str)
    Outputs: date (np.array, float) -> time data in years
            co2 (np.array, float) -> CO2 emission in ppm
            sd (np.array, float) -> instrumental standard deviations in CO2 emissions.

    Author: R.S.S.G.
    Date created: 03/10/2024
    """

    df = pd.read_csv(filename, skiprows=24)
    date = np.array(df["DATE"])
    co2 = np.array(df["CO2(ppm)"])
    sd = np.array(df["SD(ppm)"])
    return date,co2,sd





# Calling our IO function
date, co2, sd_ins = io_data(PATH+filename)


# Defining our new more realistic standard deviation
sd = 10*sd_ins





plt.figure(figsize=(14,6))

plt.plot(date, co2, color = "k", label = "Experimental Emission Data of $CO_2$")
#plt.errorbar(date, co2, yerr= sd, alpha = 0.3, marker = " ", linestyle = " ")

# Only for style, I've used this shaded region to represent standard deviation instead of the above plt.errorbar()
plt.fill_between(date, co2 - sd, co2 + sd, color='gray', alpha=0.35, label="Uncertainty ($\\sigma$)")


plt.title("$CO_2$ Emission")
plt.xlabel("$time\\ [year]$")
plt.ylabel("$CO_2 [ppm]$")
plt.legend(loc=5)

plt.grid()

plt.show()
plt.close()





plt.figure(figsize=(14,6))

plt.plot(date, co2, color = "k", label = "Experimental Emission Data of $CO_2$")

plt.fill_between(date, co2 - sd, co2 + sd, color='gray', alpha=0.35, label="Uncertainty ($\\sigma$)")


plt.title("$CO_2$ Emission")
plt.xlabel("$time\\ [year]$")
plt.ylabel("$CO_2[ppm]$")
plt.legend(loc=5)

plt.grid()

plt.xlim(1980,1990)
plt.ylim(335,350)

plt.show()
plt.close()








# Getting the coefficients
sp = st.spearmanr(date,co2)
pe = st.pearsonr(date, co2)


# Reporting these coefficients
print("Spearman Coefficient: %.5f" %sp[0])
print("Pearson Coefficient: %.5f" % pe[0])








# Our model
def model1(t,a,b):
    """
    This is a first linear model for CO2 emission as a function of time.
    Input: t (float) -> time data in years 
        parameters (tuple, float) -> free parameters a and b
    Output: y (float) -> value of the modelated CO2 emission.
    Author: R.S.S.G.
    Date created: 03/10/2024
    """
    y = a*t + b
    return y


# Defining the chi^2 stat for the 1st model
def chi_sqr_stat_m1(parameters):
    """
    This is a function that return the chi^2 stat.
    Input: parameters (tuple, float) -> free parameters
    Output: chi_sqr (float) -> value of chi^2 stat
    Author: R.S.S.G.
    Date created: 03/10/2024
    """
    a, b = parameters
    t = date
    # Physically motivated model
    phys_model = a*t + b
    
    # Use the chi^2 formula
    chi_sqr = np.sum((co2 - phys_model)**2/(sd)**2)
    return chi_sqr


# Take the ansatsz (educated guess)
initial_guess = np.array((1,-300))

# Call the minimization routine, where I've used method Powell as the minimization wouldn't terminate succesfully without it. 
res_co2 = opt.minimize(chi_sqr_stat_m1, initial_guess, method = "Powell")

# Print the result:
print("The parameters are:\n",res_co2.x)


# Check if the optimization was succesful
res_co2.success


a, b= (res_co2.x[0], res_co2.x[1])


# Print the equation
print("And the equation of the line is give by:\n y = %.4f *t - %.4f" %(a,abs(b)))


# In this case I will "sacrify resolution" and use the same experimental time data to evaluate the model
# as we'll need this co2 fitted data to have the same length as the experimental one for future tasks!  
new_co2 = model1(date, a, b)


plt.figure(figsize=(14,6))

plt.plot(date, co2, color = "k", label = "Experimental Emission Data of $CO_2$")
plt.plot(date, new_co2, color = "b", label = "Linear Model:\n y = %.6s *t - %.6s" %(a,abs(b)))

plt.fill_between(date, co2 - sd, co2 + sd, color='gray', alpha=0.35, label="Uncertainty ($\\sigma$)")


plt.title("$CO_2$ Emission")
plt.xlabel("$time\\ [year]$")
plt.ylabel("$CO_2[ppm]$")
plt.legend(loc=5)

plt.grid()

plt.show()
plt.close()





plt.figure(figsize=(14,6))

plt.plot(date, co2, color = "k", label = "Experimental Emission Data of $CO_2$")
plt.plot(date, new_co2, color = "b", label = f"Linear Model:\n y = %.5s *t - %.5s" %(a,abs(b)))

plt.fill_between(date, co2 - sd, co2 + sd, color='gray', alpha=0.35, label="Uncertainty ($\\sigma$)")


plt.title("$CO_2$ Emission")
plt.xlabel("$time\\ [year]$")
plt.ylabel("$CO_2[ppm]$")
plt.legend(loc=5)

plt.grid()
plt.xlim(1980,1990)
plt.ylim(335,350)
plt.show()
plt.close()





# Calling opt.curve_fit()
coef_chi, cova_chi = opt.curve_fit(model1, date, co2, sigma = sd)

#Uncertainties
sigma_coef = np.sqrt(np.diag(cova_chi))
# Reporting coefficients and uncertainties
print("Best-fit parameters", coef_chi)
print("Associate uncertainties:", sigma_coef)


# Defining a new co2 fitted vector with the same shape of the original date as we're going to use it later at calculating the chi^2 stat!
fit_co2 = model1(date, *coef_chi)


plt.figure(figsize=(14,13))

plt.subplot(2,1,1)
plt.plot(date, co2, color = "k", label = "Experimental Emission Data of $CO_2$")
plt.plot(date, new_co2, color = "b", label = f"Linear Model:\n y = %.7s *t - %.7s" %(a,abs(b)))
plt.plot(date, fit_co2, color = "r", label = f"Linear Model (curve_fit):\n y = %.7s *t - %.7s" %(coef_chi[0],abs(coef_chi[1])))

plt.fill_between(date, co2 - sd, co2 + sd, color='gray', alpha=0.35, label="Uncertainty ($\\sigma$)")


plt.title("$CO_2$ Emission")
plt.xlabel("$time\\ [year]$")
plt.ylabel("$CO_2[ppm]$")
plt.legend(loc=5)
plt.grid()

# Zooming in
plt.subplot(2,1,2)
plt.plot(date, co2, color = "k", label = "Experimental Emission Data of $CO_2$")
plt.plot(date, new_co2, color = "b", label = f"Linear Model:\n y = %.7s *t - %.7s" %(a,abs(b)))
plt.plot(date, fit_co2, color = "r", label = f"Linear Model (curve_fit):\n y = %.7s *t - %.7s" %(coef_chi[0],abs(coef_chi[1])))

plt.fill_between(date, co2 - sd, co2 + sd, color='gray', alpha=0.35, label="Uncertainty ($\\sigma$)")


plt.title("$CO_2$ Emission (Zooming in to try to see the difference)")
plt.xlabel("$time\\ [year]$")
plt.ylabel("$CO_2[ppm]$")
plt.legend(loc=5)

plt.xlim(1981,1981.05)
plt.ylim(335.8,336)
plt.grid()

plt.show()
plt.close()








def chi_sqr_red_stat(fex, fit, sigma):
    """
    This is a function that return the reduced chi^2 stat.
    Input: fex, fit (both are np.array that contains floats) -> experimental and fitted co2 data.
            sigma (np.array, float) -> standard deviation of experimental co2 data 
    Output: chi_sqr_red (float) -> reduced chi^2 value
    Author: R.S.S.G.
    Date created: 04/10/2024
    """

    # Use the chi^2 formula
    chi_sqr = np.sum((fex - fit)**2/(sigma)**2)
    
    # We had 2 free parameters (a,b) and then
    # nu = N - #param
    nu = len(fex) - 2

    chi_sqr_red = chi_sqr/nu

    return chi_sqr_red





# Compute the reduced chi^2 stat using the fit_co2 vector we create previously
chi_red_1 = chi_sqr_red_stat(co2, new_co2, sd)

# Print reduced chi^2 value
print("The reduced chi squared is: ", chi_red_1)





# Just to see if there's a difference with the values obtained with curve_fit and the manual minimization.
print("The reduced chi squared (using opt.curve_fit()) is: ", chi_sqr_red_stat(co2, fit_co2, sd))

# Let's get the difference between them
print("Difference between reduced chi square stats: ", chi_red_1 - chi_sqr_red_stat(co2, fit_co2, sd), "\nWe can see that it's super tiny, and we can consider both as the same")












def model2(t, a, b):
    """
    This is a quartic polynomial of t model for CO2 emission as a function of time.
    Input: t (float) -> time data in years 
        parameters (tuple, float) -> free parameters a and b
    Output: y (float) -> value of the modelated CO2 emission.
    Author: R.S.S.G.
    Date created: 04/10/2024
    """
    y = (a*(t**4)) + b
    return y 





coef_chi2, cova_chi2 = opt.curve_fit(model2, date, co2, sigma = sd, p0 = [1,-400])

#Uncertainties
sigma_coef2 = np.sqrt(np.diag(cova_chi2))

# Reporting
print("Best-fit parameters:", coef_chi2)

print("Associate uncertainties:", sigma_coef2)


# Again, using our coefficients and the second model, we define a vector with the fitted values (same length of date as we're going to need that later)
new_co2_2 = model2(date, *coef_chi2)


plt.figure(figsize=(14,13))

plt.subplot(2,1,1)
plt.plot(date, co2, color = "k", label = "Experimental Data")
plt.plot(date, new_co2, color = "b", label = "Linear Model")
plt.plot(date, new_co2_2, color = "r", label = "4th power of t Model")

plt.fill_between(date, co2 - sd, co2 + sd, color='gray', alpha=0.35, label="Uncertainty ($\\sigma$)")


plt.title("$CO_2$ Emission")
plt.xlabel("$time\\ [year]$")
plt.ylabel("$CO_2[ppm]$")
plt.legend(loc=5)

plt.grid()
# Zooming in
plt.subplot(2,1,2)
plt.plot(date, co2, color = "k", label = "Experimental Data")
plt.plot(date, new_co2, color = "b", label = "Linear Model")
plt.plot(date, new_co2_2, color = "r", label = "4th power of t Model")

plt.fill_between(date, co2 - sd, co2 + sd, color='gray', alpha=0.35, label="Uncertainty ($\\sigma$)")


plt.title("$CO_2$ Emission (Zooming in to see the difference)")
plt.xlabel("$time\\ [year]$")
plt.ylabel("$CO_2[ppm]$")
plt.legend(loc=5)

plt.xlim(1981,1981.1)
plt.ylim(335,338)
plt.grid()

plt.show()
plt.close()


# Let's get its reduced chi squared statistic 
# Compute the reduced chi^2 stat
chi_red_2 = chi_sqr_red_stat(co2, new_co2_2, sd)

# Print reduced chi^2 value
print("The reduced chi squared is: ", chi_red_2)





def chi_sqr_stat_m2(parameters):
    """
    This is a function that return the chi^2 stat for our quartic model.
    Input: parameters (tuple, float) -> free parameters
    Output: chi_sqr (float) -> value of chi^2 stat
    Author: R.S.S.G.
    Date created: 04/10/2024
    """
    a, b = parameters
    t = date
    # Physically motivated model
    phys_model = a*(t**4)+b
    
    # Use the chi^2 formula
    chi_sqr = np.sum((co2 - phys_model)**2/(sd)**2)
    return chi_sqr


# Take the initial guess -> ansatsz (educated guess)
initial_guess = np.array([1,-400])

# Call the minimisation routine.
# I've used method = "Nelder-Mead" as without it, the optimization wouldn't terminate succesfully
res_co2_2 = opt.minimize(chi_sqr_stat_m2, initial_guess, method = "Nelder-Mead")

# Print the result:
print("The parameters are:\n",res_co2_2.x)


# Check if the optimization was succesful
res_co2_2.message


#  We need the same length for experimental and fitted data
fit_co2_2 = model2(date, res_co2_2.x[0], res_co2_2.x[1])

# Compute the reduced chi^2 stat
chi_red_22 = chi_sqr_red_stat(co2, fit_co2_2, sd)

# Print reduced chi^2 value
print("The reduced chi squared is: ", chi_red_22)


# Let's get the difference between in this model
print("Difference between reduced chi square stats: ", abs(chi_red_2 - chi_red_22), "\nWe can see that it's super tiny, and we can consider both as the same, again as expected.")









# First, let's define our parameters for the first and second model
a_1, b_1 = coef_chi[0],coef_chi[1]
a_2, b_2 = coef_chi2[0], coef_chi2[1]

# Then, define its uncertainties from the covariance matrix to use them as bounds.
sa_1, sb_1 = tuple(sigma_coef)
sa_2, sb_2 = tuple(sigma_coef2)

# So let's define the vectors with values around the free parameters
a_mult1 = np.linspace(a_1 - sa_1, a_1 + sa_1, len(date))
b_mult1 = np.linspace(b_1 - sb_1, b_1 + sb_1, len(date))
a_mult2 = np.linspace(a_2 - sa_2, a_2 + sa_2, len(date))
b_mult2 = np.linspace(b_2 - sb_2, b_2 + sb_2, len(date))

# Now, we create a meshgrid
A1_2D, B1_2D = np.meshgrid(a_mult1, b_mult1)
A2_2D, B2_2D = np.meshgrid(a_mult2, b_mult2)


# Implementing it in a function. I've defined previously some parts of the function outside as I wanted to get some curves.
def chi_sqrt_2D(parameters, uncertainties, date, chi_stat):
    """
    This is a function that returns the 2D chi^2 stat surface for the each model.
    As it uses as input the previously defined chi^2 stats for each model, it can compute the surfaces for both models 
    Input: parameters (tuple, float) -> optimal free parameters
        uncertainties (tuple, float) -> uncertainties of the optimal free parameters
        date (np.array, float) -> time data array, we just need it to get the length of it
        chi_stat (function) -> this is the prevously defined 1D chi^2 stat for each model
    Output: chi (2D np.array, float) -> 2D surface of chi^2 stat. 
    Author: R.S.S.G.
    Date created: 04/10/2024
    """
    # Get the parameters
    a, b = parameters
    sa, sb = uncertainties
    
    # So let's define the vectors with values around the free parameters
    a_mult = np.linspace(a - sa, a + sa, len(date))
    b_mult = np.linspace(b - sb, b + sb, len(date))

    # Now, we create a meshgrid
    A_2D, B_2D = np.meshgrid(a_mult, b_mult)
    
    # Empty matrix ready to receive the values for the surface
    chi = np.zeros_like(A_2D)
    
    # Now, we iterate through the matrix elements of chi
    # Each element will have the chi^2 value for specific a and b
    for i in range(chi.shape[0]):
        for j in range(chi.shape[1]):
            chi[i,j] = chi_stat((A_2D[i,j],B_2D[i,j]))

    return chi


# This was part of a bunch of trials in order to get reasonable parameters for the previous part
# chi_v = []
# for i in range(len(a_mult1)):
#     chi_v.append(chi_sqr_stat_m1((a_1,b_mult1[i])))

# chi_v = np.array(chi_v)
# plt.plot(b_mult1,chi_v)
# plt.plot(b_1, chi_sqr_stat_m1((a_1,b_1)), color = "red", linestyle = " ",marker = "d")








# Calling our surface computing function using the chi^2 stat for the first model.
chi_m1 = chi_sqrt_2D((a_1, b_1), (sa_1, sb_1), date, chi_sqr_stat_m1)





# Let's get some fixed value arrays
a_c1 = np.ones(a_mult1.shape)*a_1
b_c1 = np.ones(b_mult1.shape)*b_1

# Now, to get the curves
curve_a1 = []
curve_b1 = []
for i in range(a_c1.shape[0]):
    curve_a1.append(chi_sqr_stat_m1((a_c1[i],b_mult1[i])))
    curve_b1.append(chi_sqr_stat_m1((a_mult1[i],b_c1[i])))
curve_a1 = np.array(curve_a1)
curve_b1 = np.array(curve_b1)


plt.figure(figsize=(7,7))

# We'll use Mega for the Chi^2 values 
Z = plt.pcolor(A1_2D, B1_2D*(10**(-3)), (chi_m1)*(10**(-6)), cmap = "magma_r")

plt.plot(a_1,b_1*(10**(-3)),marker="o", color = "k", label = "Minimum", linestyle = " ")
plt.plot(a_c1, b_mult1*(10**(-3)), color = "r", linestyle = "--")
plt.plot(a_mult1, b_c1*(10**(-3)), color = "r", linestyle = "--")

# Add a colour bar
plt.colorbar(Z, label = "M$\\chi^2_1$")

# Axes labels
plt.xlabel("$a_1$")
plt.ylabel("k$b_1$")

plt.legend()

plt.show()


fig = plt.figure(figsize=(9,9))
ax = fig.add_subplot(111, projection='3d')

ax.scatter(a_1, b_1*(10**(-3)), chi_sqr_stat_m1((a_1,b_1))*(10**(-6)), color='k', s=200, label = "Mininum")
ax.plot_surface(A1_2D, B1_2D*(10**(-3)), (chi_m1)*(10**(-6)), cmap = 'magma_r', label = "$\\chi^2_1$ Surface", alpha = 0.8)
ax.plot(a_c1,b_mult1*(10**(-3)),(curve_a1)*(10**(-6)),color='red', linewidth=3, linestyle = "--", label="1D curve for fixed $a_1$")
ax.plot(a_mult1,b_c1*(10**(-3)),(curve_b1)*(10**(-6)),color='red', linewidth=3, linestyle = "--", label="1D curve for fixed $b_1$")

# Axes labels
ax.set_xlabel("$a_1$")
ax.set_ylabel("k$b_1$")
ax.set_zlabel("M$\\chi^2_1$")

plt.legend(loc=7)

ax.view_init(30,20)
plt.show()





# Calling our surface computing function using the chi^2 stat for the second model.
chi_m2 = chi_sqrt_2D((a_2, b_2), (sa_2, sb_2), date, chi_sqr_stat_m2)


# Again, let's do some curves
a_c2 = np.ones(a_mult2.shape)*a_2
b_c2 = np.ones(b_mult2.shape)*b_2
curve_a2 = []
curve_b2 = []
for i in range(a_c2.shape[0]):
    curve_a2.append(chi_sqr_stat_m2((a_c2[i],b_mult2[i])))
    curve_b2.append(chi_sqr_stat_m2((a_mult2[i],b_c2[i])))
curve_a2 = np.array(curve_a2)
curve_b2 = np.array(curve_b2)


plt.figure(figsize=(7,7))

Z2 = plt.pcolor(A2_2D*(10**(12)), B2_2D*(10**(-3)), (chi_m2)*(10**(-3)), cmap = "summer_r")

plt.plot(a_2*(10**(12)),b_2*(10**(-3)),marker="d", color = "k", label = "Minimum", linestyle = " ")
plt.plot(a_c2*(10**(12)), b_mult2*(10**(-3)), color = "r", linestyle = "--")
plt.plot(a_mult2*(10**(12)), b_c2*(10**(-3)), color = "r", linestyle = "--")

# Add a colour bar
plt.colorbar(Z2, label = "k$\\chi^2_2$")

# Axes labels, as "a" is tiny, we use pico units
plt.xlabel("p$a_2$")
plt.ylabel("k$b_2$")

plt.legend()

plt.show()


fig2 = plt.figure(figsize=(9,9))
ax2 = fig2.add_subplot(111, projection='3d')

ax2.scatter(a_2*(10**(12)), b_2*(10**(-3)), chi_sqr_stat_m2((a_2,b_2))*(10**(-3)), color='k', s=200, label = "Mininum", marker = "d")
ax2.plot_surface(A2_2D*(10**(12)), B2_2D*(10**(-3)), (chi_m2)*(10**(-3)), cmap = "summer_r", label = "$\\chi^2_2$ Surface", alpha = 0.9)
ax2.plot(a_c2*(10**(12)),b_mult2*(10**(-3)),(curve_a2)*(10**(-3)),color='red', linewidth=3, linestyle = "--", label="1D curve for fixed $a_2$")
ax2.plot(a_mult2*(10**(12)),b_c2*(10**(-3)),(curve_b2)*(10**(-3)),color='red', linewidth=3, linestyle = "--", label="1D curve for fixed $b_2$")

# Axes labels
ax2.set_xlabel("p$a_2$")
ax2.set_ylabel("k$b_2$")
ax2.set_zlabel("k$\\chi^2_2$")
plt.legend(loc=7)

ax2.view_init(35,70)
plt.show()








# Define the confidence levels values corresponding to 0.5%, 30%, 60% and 95%.
confidence_levels1 = np.array([np.quantile(chi_m1, 0.005), np.quantile(chi_m1, 0.30), np.quantile(chi_m1, 0.6),np.quantile(chi_m1, 0.95)])*(10**(-6))
confidence_levels2 = np.array([np.quantile(chi_m2, 0.005), np.quantile(chi_m2, 0.30), np.quantile(chi_m2, 0.6),np.quantile(chi_m2, 0.95)])*(10**(-3))


# This is our testing for the contour plots! 
# plt.figure(figsize=(7,7))

# Z = plt.pcolor(A1_2D, B1_2D*(10**(-3)), (chi_m1)*(10**(-6)), cmap = "magma_r")

# # Add contour
# CS = plt.contour(A1_2D,B1_2D*(10**(-3)),(chi_m1)*(10**(-6)), levels=confidence_levels, colors = ["r","g","b","w"])

# plt.plot(a_1,b_1*(10**(-3)),marker="o", color = "k", label = "Minimum", linestyle = " ")

# # Add a colour bar
# plt.colorbar(Z, label = "M$\\chi^2_1$")

# # Level's label
# fmt = {}
# strs = ['0.5%', '30%', '60%', '95%']
# for l, s in zip(CS.levels, strs):
#     fmt[l] = s

# plt.clabel(CS, CS.levels, inline=True, fmt=fmt, fontsize=10)


# # Axes labels
# plt.xlabel("$a_1$")
# plt.ylabel("k$b_1$")

# plt.legend(loc = (0.73, 0.7))

# plt.show()



# Create a figure with multiple panels
fig = plt.figure(figsize=(14, 12))

plt.suptitle("2D $\\chi^2$ surface for each model")


# Panel 1: 3D plot
ax1 = fig.add_subplot(221, projection='3d')  # 2 rows, 2 columns, 2nd subplot

ax1.scatter(a_1, b_1*(10**(-3)), chi_sqr_stat_m1((a_1,b_1))*(10**(-6)), color='k', s=200, label = "Mininum")
ax1.plot_surface(A1_2D, B1_2D*(10**(-3)), (chi_m1)*(10**(-6)), cmap = 'magma_r', label = "$\\chi^2_1$ Surface", alpha = 0.8)
ax1.plot(a_c1,b_mult1*(10**(-3)),(curve_a1)*(10**(-6)),color='red', linewidth=3, linestyle = "--", label="1D curve for fixed $a_1$")
ax1.plot(a_mult1,b_c1*(10**(-3)),(curve_b1)*(10**(-6)),color='red', linewidth=3, linestyle = "--", label="1D curve for fixed $b_1$")

# Axes labels
ax1.set_xlabel("$a_1$")
ax1.set_ylabel("k$b_1$")
ax1.set_zlabel("M$\\chi^2_1$")

ax1.legend(loc = "upper left")

ax1.view_init(35,15)

# Panel 2: 2D plot
ax2 = fig.add_subplot(222)  # 2 rows, 2 columns, 1st subplot
Z = ax2.pcolor(A1_2D, B1_2D*(10**(-3)), (chi_m1)*(10**(-6)), cmap = "magma_r")


# Add contour
CS = plt.contour(A1_2D,B1_2D*(10**(-3)),(chi_m1)*(10**(-6)), levels=confidence_levels1, colors = ["r","g","b","w"])

ax2.plot(a_1,b_1*(10**(-3)),marker="o", color = "k", label = "Minimum", linestyle = " ")

# Add a colour bar
plt.colorbar(Z, label = "M$\\chi^2_1$")

# Level's label
fmt = {}
strs = ['0.5%', '30%', '60%', '95%']
for l, s in zip(CS.levels, strs):
    fmt[l] = s

plt.clabel(CS, CS.levels, inline=True, fmt=fmt, fontsize=10)

ax2.legend(loc = (0.73, 0.7))


# Axes labels
ax2.set_xlabel("$a_1$")
ax2.set_ylabel("k$b_1$")

# Panel 3: 3D plot
ax3 = fig.add_subplot(223, projection='3d')

ax3.scatter(a_2*(10**(12)), b_2*(10**(-3)), chi_sqr_stat_m2((a_2,b_2))*(10**(-3)), color='k', s=200, label = "Mininum", marker = "d")
ax3.plot_surface(A2_2D*(10**(12)), B2_2D*(10**(-3)), (chi_m2)*(10**(-3)), cmap = "summer_r", label = "$\\chi^2_2$ Surface", alpha = 0.8)
ax3.plot(a_c2*(10**(12)),b_mult2*(10**(-3)),(curve_a2)*(10**(-3)),color='red', linewidth=3, linestyle = "--", label="1D curve for fixed $a_2$")
ax3.plot(a_mult2*(10**(12)),b_c2*(10**(-3)),(curve_b2)*(10**(-3)),color='red', linewidth=3, linestyle = "--", label="1D curve for fixed $b_2$")

# Axes labels
ax3.set_xlabel("p$a_2$")
ax3.set_ylabel("k$b_2$")
ax3.set_zlabel("k$\\chi^2_2$")
ax3.legend(loc= "upper left")

ax3.view_init(35,70)

# Panel 4: 2D plot
ax4 = fig.add_subplot(224)  # 2 rows, 2 columns, 1st subplot
Z2 = plt.pcolor(A2_2D*(10**(12)), B2_2D*(10**(-3)), (chi_m2)*(10**(-3)), cmap = "summer_r")
# Add contour
CS2 = plt.contour(A2_2D*(10**(12)), B2_2D*(10**(-3)), (chi_m2)*(10**(-3)), levels=confidence_levels2, colors = ["r","g","b","w"])

ax4.plot(a_2*(10**(12)),b_2*(10**(-3)),marker="d", color = "k", label = "Minimum", linestyle = " ")

# Level's label
fmt2 = {}
strs2 = ['0.5%', '30%', '60%', '95%']
for l, s in zip(CS2.levels, strs2):
    fmt2[l] = s
    
plt.clabel(CS2, CS2.levels, inline=True, fmt=fmt2, fontsize=10)

# Add a colour bar
plt.colorbar(Z2, label = "k$\\chi^2_2$")

# Axes labels, as "a" is tiny, we use pico units
ax4.set_xlabel("p$a_2$")
ax4.set_ylabel("k$b_2$")
ax4.legend(loc = (0.73, 0.7))

plt.tight_layout()
plt.show()











# Defining filenames
filenameCH4 = "CapeGrim_CH4_data_download.csv"
filenameN2O = "CapeGrim_N2O_data_download.csv"

# Inspecting the data with vim, we can see that there are 24 rows as headers.
# df = pd.read_csv(PATH+filenameN2O, skiprows=24)
# df


def io_data_CH4(filename):
    """
    This is an I/O function that opens a file with data
    and return data arrays.
    Input: filename (str)
    Outputs: date (np.array, float) -> time data in years
            ch4 (np.array, float) -> CH4 emission in ppb
            sd (np.array, float) -> instrumental standard deviations in CH4 emissions.

    Author: R.S.S.G.
    Date created: 20/09/2024
    """
    df = pd.read_csv(filename, skiprows=24)
    date = np.array(df["DATE"])
    ch4 = np.array(df["CH4(ppb)"])
    sd = np.array(df["SD(ppb)"])
    return date,ch4,sd

def io_data_N2O(filename):
    """
    This is an I/O function that opens a file with data
    and return data arrays.
    Input: filename (str)
    Outputs: date (np.array, float) -> time data in years
            ch4 (np.array, float) -> CH4 emission in ppb
            sd (np.array, float) -> instrumental standard deviations in CH4 emissions.

    Author: R.S.S.G.
    Date created: 20/09/2024
    """
    df = pd.read_csv(filename, skiprows=24)
    date = np.array(df["DATE"])
    n2o = np.array(df["N2O(ppb)"])
    sd = np.array(df["SD(ppb)"])
    return date,n2o,sd



# Using the previously defined IO functions.
date_CH4, ch4, sd_ins_ch4 = io_data_CH4(PATH + filenameCH4)
date_N2O, n2o, sd_ins_n2o = io_data_N2O(PATH + filenameN2O)


# Defining the more realistic standard deviation
sd_CH4 = 10*sd_ins_ch4
sd_N2O = 10*sd_ins_n2o


plt.figure(figsize=(12,6))

plt.plot(date_CH4, ch4, color = "g", label = "Experimental Data $CH_4$")

plt.fill_between(date_CH4, ch4 - sd_CH4, ch4 + sd_CH4, color='g', alpha=0.2, label="Uncertainty ($\\sigma_{CH_4}$)")

plt.title("$CH_4$ Emissions")
plt.xlabel("$time\\ [year]$")
plt.ylabel("$Emission [ppb]$")
plt.legend(loc=5)

plt.grid()

plt.show()
plt.close()


plt.figure(figsize=(12,6))

plt.plot(date_N2O, n2o, color = "b", label = "Experimental Data $N_2O$")

plt.fill_between(date_N2O, n2o - sd_N2O, n2o + sd_N2O, color='b', alpha=0.2, label="Uncertainty ($\\sigma_{N_2O}$)")

plt.title("$N_2O$ Emissions")
plt.xlabel("$time\\ [year]$")
plt.ylabel("$Emission [ppb]$")
plt.legend(loc=5)

plt.grid()

plt.show()
plt.close()





fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (19,3.5),sharex = True)
fig.suptitle('Emissions')

ax1.plot(date, co2, color = "k", label = "Experimental Data $CO_2$")
ax1.set_ylabel("k$CO_2$ [ppb]")
ax1.fill_between(date, co2 - sd, co2 + sd, color='gray', alpha=0.35, label="Uncertainty ($\\sigma_{CO_2}$)")


ax2.plot(date_CH4, ch4, color = "g", label = "Experimental Data $CH_4$")
ax2.set_ylabel("$CH_4$ [ppb]")
ax2.fill_between(date_CH4, ch4 - sd_CH4, ch4 + sd_CH4, color='g', alpha=0.2, label="Uncertainty ($\\sigma_{CH_4}$)")


ax3.plot(date_N2O, n2o, color = "b", label = "Experimental Data $N_2O$")
ax3.set_ylabel("$N_2O$ [ppb]")
ax3.fill_between(date_N2O, n2o - sd_N2O, n2o + sd_N2O, color='b', alpha=0.2, label="Uncertainty ($\\sigma_{N_2O}$)")


ax1.legend()
ax2.legend()
ax3.legend()
ax1.set_xlabel("time [year]")
ax2.set_xlabel("time [year]")
ax3.set_xlabel("time [year]")

plt.show()








# Defining alpha, beta and gamma constants with the typical values.
alpha = 5.35 #[W/m^2]
beta = 0.036 #[W/m^2]
gamma = 0.12 #[W/m^2]

# Define the preindustrial concentrations.
c_0 = 280
m_0 = 700
n_0 = 270

# Obtaining the values for the radiative forcing  
f_co2 = alpha*np.log((co2/c_0))
f_ch4 = beta*(np.sqrt(ch4) - np.sqrt(m_0))
f_n2o = gamma*(np.sqrt(n2o) - np.sqrt(n_0))





# We need to define by error propagation the uncertainties.
# For CO2
sigma_fco2 = alpha*(np.abs(sd/co2))

# For CH4
sigma_fch4 = (beta*np.abs(sd_CH4))/(2*np.sqrt(np.abs(ch4)))

# For CH4
sigma_fn2o = (gamma*np.abs(sd_N2O))/(2*np.sqrt(np.abs(n2o)))



fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (18,4.5))
fig.suptitle('Radiative Forcings')

ax1.plot(date, f_co2, color = "k", label = "$\\Delta F_{CO_2}$")
ax1.fill_between(date, f_co2 - 3*sigma_fco2, f_co2 + 3*sigma_fco2, color='gray', alpha=0.35, label="$3\\sigma_{\\Delta F_{CO_2}}$")
ax1.grid()

ax2.plot(date_CH4, f_ch4, color = "g", label = "$\\Delta F_{CH_4}$")
ax2.fill_between(date_CH4, f_ch4 - 3*sigma_fch4, f_ch4 + 3*sigma_fch4, color='g', alpha=0.2, label="$3\\sigma_{\\Delta F_{CH_4}}$")
ax2.grid()

ax3.plot(date_N2O, f_n2o, color = "b", label = "$\\Delta F_{N_2O}$")
ax3.fill_between(date_N2O, f_n2o - 3*sigma_fn2o, f_n2o + 3*sigma_fn2o, color='b', alpha=0.2, label="$3\\sigma_{\\Delta F_{N_2O}}$")
ax3.grid()

ax1.legend()
ax2.legend()
ax3.legend()
ax1.set_xlabel("time [year]")
ax2.set_xlabel("time [year]")
ax3.set_xlabel("time [year]")
ax1.set_ylabel("$\\Delta F \\, [\\frac{W}{m^2}]$")
ax2.set_ylabel("$\\Delta F \\, [\\frac{W}{m^2}]$")
ax3.set_ylabel("$\\Delta F \\, [\\frac{W}{m^2}]$")

plt.tight_layout()
plt.show()





fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (18,4.5),sharey = True, sharex = True)
fig.suptitle('Radiative Forcings')

ax1.plot(date, f_co2, color = "k", label = "$\\Delta F_{CO_2}$")
ax1.fill_between(date, f_co2 - 3*sigma_fco2, f_co2 + 3*sigma_fco2, color='gray', alpha=0.35, label="$3\\sigma_{\\Delta F_{CO_2}}$")
ax1.grid()

ax2.plot(date_CH4, f_ch4, color = "g", label = "$\\Delta F_{CH_4}$")
ax2.fill_between(date_CH4, f_ch4 - 3*sigma_fch4, f_ch4 + 3*sigma_fch4, color='g', alpha=0.2, label="$3\\sigma_{\\Delta F_{CH_4}}$")
ax2.grid()

ax3.plot(date_N2O, f_n2o, color = "b", label = "$\\Delta F_{N_2O}$")
ax3.fill_between(date_N2O, f_n2o - 3*sigma_fn2o, f_n2o + 3*sigma_fn2o, color='b', alpha=0.2, label="$3\\sigma_{\\Delta F_{N_2O}}$")
ax3.grid()

ax1.legend()
ax2.legend()
ax3.legend()
ax1.set_xlabel("time [year]")
ax2.set_xlabel("time [year]")
ax3.set_xlabel("time [year]")
ax1.set_ylabel("$\\Delta F \\, [\\frac{W}{m^2}]$")
ax2.set_ylabel("$\\Delta F \\, [\\frac{W}{m^2}]$")
ax3.set_ylabel("$\\Delta F \\, [\\frac{W}{m^2}]$")

plt.tight_layout()
plt.show()








# Let's get a common range by looking at the max and min values
# We need to have a range shared by the three arrays in order to get the interpolation working 
print(np.max([date[0],date_CH4[0],date_N2O[0]]))
print(np.min([date[-1],date_CH4[-1],date_N2O[-1]]))


# Generating a new time array. Where the range goes from the min and max values.
# Notice that this array will have less resolution as it only has a 1-year spacing between elements!
# We may want to have this time array to be whole numbers for the future tasks!
new_date = np.arange(int(np.max([date[0],date_CH4[0],date_N2O[0]]))+1,(np.min([date[-1],date_CH4[-1],date_N2O[-1]])),1)

# Checking if the array has a 1-year spacing and also its shape.
print(new_date, new_date.shape)


# As we have time series, we'll use interp.interp1d
# We've chosen linear kind as it seems to be the natural choice looking at the plots!

int_fco2 = interp.interp1d(date, f_co2, kind = "linear")
int_fch4 = interp.interp1d(date_CH4, f_ch4, kind = "linear")
int_fn2o = interp.interp1d(date_N2O, f_n2o, kind = "linear")


new_fco2 = int_fco2(new_date)
new_fch4 = int_fch4(new_date)
new_fn2o = int_fn2o(new_date)


fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (18,4.5),sharey = True, sharex = True)
fig.suptitle('Radiative Forcings')

ax1.plot(date, f_co2, color = "k", label = "$\\Delta F_{CO_2}$")
ax1.plot(new_date, new_fco2, color = "brown", label = "Interpolated $\\Delta F_{CO_2}$")

ax1.fill_between(date, f_co2 - 3*sigma_fco2, f_co2 + 3*sigma_fco2, color='gray', alpha=0.35, label="$3\\sigma_{\\Delta F_{CO_2}}$")
ax1.grid()

ax2.plot(date_CH4, f_ch4, color = "g", label = "$\\Delta F_{CH_4}$")
ax2.plot(new_date, new_fch4, color = "violet", label = "Interpolated $\\Delta F_{CH_4}$")
ax2.fill_between(date_CH4, f_ch4 - 3*sigma_fch4, f_ch4 + 3*sigma_fch4, color='g', alpha=0.2, label="$3\\sigma_{\\Delta F_{CH_4}}$")
ax2.grid()

ax3.plot(date_N2O, f_n2o, color = "b", label = "$\\Delta F_{N_2O}$")
ax3.plot(new_date, new_fn2o, color = "magenta", label = "Interpolated $\\Delta F_{CH_4}$")
ax3.fill_between(date_N2O, f_n2o - 3*sigma_fn2o, f_n2o + 3*sigma_fn2o, color='b', alpha=0.2, label="$3\\sigma_{\\Delta F_{N_2O}}$")
ax3.grid()

ax1.legend()
ax2.legend()
ax3.legend()
ax1.set_xlabel("time [year]")
ax2.set_xlabel("time [year]")
ax3.set_xlabel("time [year]")
ax1.set_ylabel("$\\Delta F \\, [\\frac{W}{m^2}]$")
ax2.set_ylabel("$\\Delta F \\, [\\frac{W}{m^2}]$")
ax3.set_ylabel("$\\Delta F \\, [\\frac{W}{m^2}]$")
plt.xlim(np.min([date[0],date_CH4[0],date_N2O[0]])-1,np.max([date[-1],date_CH4[-1],date_N2O[-1]])+1)

plt.tight_layout()
plt.show()





plt.figure(figsize = (18,7))
plt.title('Radiative Forcings')

plt.plot(date, f_co2, color = "k", label = "$\\Delta F_{CO_2}$")
plt.plot(new_date, new_fco2, color = "brown", label = "Interpolated $\\Delta F_{CO_2}$")

plt.fill_between(date, f_co2 - 3*sigma_fco2, f_co2 + 3*sigma_fco2, color='gray', alpha=0.35, label="$3\\sigma_{\\Delta F_{CO_2}}$")

plt.plot(date_CH4, f_ch4, color = "g", label = "$\\Delta F_{CH_4}$")
plt.plot(new_date, new_fch4, color = "violet", label = "Interpolated $\\Delta F_{CH_4}$")
plt.fill_between(date_CH4, f_ch4 - 3*sigma_fch4, f_ch4 + 3*sigma_fch4, color='g', alpha=0.2, label="$3\\sigma_{\\Delta F_{CH_4}}$")

plt.plot(date_N2O, f_n2o, color = "b", label = "$\\Delta F_{N_2O}$")
plt.plot(new_date, new_fn2o, color = "magenta", label = "Interpolated $\\Delta F_{CH_4}$")
plt.fill_between(date_N2O, f_n2o - 3*sigma_fn2o, f_n2o + 3*sigma_fn2o, color='b', alpha=0.2, label="$3\\sigma_{\\Delta F_{N_2O}}$")

plt.xlabel("time [year]")
plt.ylabel("$\\Delta F \\, [\\frac{W}{m^2}]$")

plt.xlim(np.min([date[0],date_CH4[0],date_N2O[0]]),np.max([date[-1],date_CH4[-1],date_N2O[-1]])+0.5)

plt.legend(loc=7)

plt.grid()

plt.show()





plt.figure(figsize = (18,9))
plt.title('Radiative Forcings')

plt.plot(date, f_co2, color = "k", label = "$\\Delta F_{CO_2}$")
plt.plot(new_date, new_fco2, color = "brown", label = "Interpolated $\\Delta F_{CO_2}$")
plt.fill_between(date, f_co2 - 3*sigma_fco2, f_co2 + 3*sigma_fco2, color='gray', alpha=0.35, label="$3\\sigma_{\\Delta F_{CO_2}}$")

plt.plot(date_CH4, f_ch4, color = "g", label = "$\\Delta F_{CH_4}$")
plt.plot(new_date, new_fch4, color = "violet", label = "Interpolated $\\Delta F_{CH_4}$")
plt.fill_between(date_CH4, f_ch4 - 3*sigma_fch4, f_ch4 + 3*sigma_fch4, color='g', alpha=0.2, label="$3\\sigma_{\\Delta F_{CH_4}}$")

plt.plot(date_N2O, f_n2o, color = "b", label = "$\\Delta F_{N_2O}$")
plt.plot(new_date, new_fn2o, color = "magenta", label = "Interpolated $\\Delta F_{CH_4}$")
plt.fill_between(date_N2O, f_n2o - 3*sigma_fn2o, f_n2o + 3*sigma_fn2o, color='b', alpha=0.2, label="$3\\sigma_{\\Delta F_{N_2O}}$")

plt.xlabel("time [year]")
plt.ylabel("$\\Delta F \\, [\\frac{W}{m^2}]$")

plt.xlim(1980,1986)
plt.ylim(0,1.18)

plt.legend(loc=(0.85,0.5))

plt.grid()

plt.show()





# Now we sum all the contributions
f_total = new_fco2 + new_fch4 + new_fn2o


plt.figure(figsize=(15,6))

plt.plot(new_date, f_total, color = "r", label = "Total Radiative Forcing $\\Delta F_{total}$")

plt.title("Global Radiative Forcing")
plt.xlabel("$time\\ [year]$")
plt.ylabel("$\\Delta F \\, [\\frac{W}{m^2}]$")


plt.xlim(new_date[0]-0.5, new_date[-1]+0.5)
plt.legend(loc=5)

plt.grid()

plt.show()
plt.close()











filename_temp = "temperature-anomaly.csv"


# Procedural coding
#pd.read_csv(PATH+filename_temp)[pd.read_csv(PATH+filename_temp)["Entity"]=="Southern Hemisphere"]#["Median temperature anomaly from 1961-1990 average"]#[pd.read_csv(PATH+filename_temp)["Year"] >= 1961][pd.read_csv(PATH+filename_temp)["Year"] <= 1990]


def io_data_temp(filename):
    """
    This is an I/O function that opens a file with data
    and return data arrays.
    Input: filename (str)
    Outputs: mean (np.array, float) -> median temperature anomaly 
            y_err (np.array, float) -> symmetric 2 sigma 
            time (np.array, float) -> year
    Author: R.S.S.G.
    Date created: 08/10/2024
    """
    df = pd.read_csv(filename)
    mean = np.array(df[df["Entity"] == "Southern Hemisphere"]["Median temperature anomaly from 1961-1990 average"])
    upper_bound =  np.array(df[df["Entity"] == "Southern Hemisphere"]["Upper bound (95% CI)"])
    lower_bound =  np.array(df[df["Entity"] == "Southern Hemisphere"]["Lower bound (95% CI)"])
    # To return symmetric errors, I've take the difference instead of the average.
    y_err = np.abs((upper_bound - lower_bound)/2)
    
    return mean, y_err


sea_mean, sea_err = io_data_temp(PATH+filename_temp)





# Generating a new time/year vector from 1850 to 2019
sea_date = np.arange(1850, 2020, 1)


plt.figure(figsize=(18,7))

plt.plot(sea_date, sea_mean, color = "k", label = "Median temperature anomaly\nfrom 1961-1990 average [$\\degree C$]", linestyle = "-", marker = ".")
plt.fill_between(sea_date, sea_mean - sea_err, sea_mean + sea_err, color='gray', alpha = 0.5, label="Symmetric $2\\, \\sigma$ errors")

plt.title("Sea Temperature Anomaly")
plt.xlabel("$time\\ [year]$")
plt.ylabel("T [$\\degree C$]")

plt.legend(loc=5)

plt.grid()

plt.show()
plt.close()








print("The minimum common value in the date arrays for the total radiative forcing and sea data is: ", np.max([new_date[0], sea_date[0]]), "\nThe maximum value is: ", np.min([new_date[-1], sea_date[-1]]))


# Defining the common time range
time_range = np.arange(np.max([new_date[0], sea_date[0]]),np.min([new_date[-1], sea_date[-1]])+1,1)


#time_range


# Using conditionals to get the indexes of the overlapping time periods
ind_sea = np.where((sea_date >= np.max(([new_date[0], sea_date[0]]))) & (sea_date <= np.min([new_date[-1], sea_date[-1]])))
ind_new = np.where((new_date >= np.max(([new_date[0], sea_date[0]]))) & (new_date <= np.min([new_date[-1], sea_date[-1]])))
# Extracting the indexes as arrays
ind_sea = ind_sea[0]
ind_new = ind_new[0]


# Getting the values of total forcing, sea temperature and two sigma symmetric  anomaly in the common time range.
f_total_c = f_total[ind_new]
sea_mean_c = sea_mean[ind_sea]
sea_err_c = sea_err[ind_sea]


# So, both f_total and sea_mean with the obtained indexes should have the same length as they cover the same time range
print(f_total_c.shape,sea_mean_c.shape, sea_err_c.shape)


# Creating a dictionary to then convert it to a pandas dataframe
dfdic = {"Year": time_range, "Total radiative forcing": f_total_c, "Sea temperature anomaly": sea_mean_c, "2 sigma error in the sea temperature anomaly": sea_err_c }


# Getting the Pandas DataFrame
df = pd.DataFrame(dfdic)
#df


# Creating a correlation.csv file
df.to_csv("correlation.csv", index = False)





plt.figure(figsize=(17,7))

plt.scatter(f_total_c, sea_mean_c, color = "k", label = "Sea Temperature Anomaly")
plt.errorbar(f_total_c, sea_mean_c, yerr = sea_err_c, color = "darkslategray", linestyle = " ", marker = " ",label = "$2\\sigma$ symmetric errors")

plt.title("Sea Temperature Anomaly  vs Global Radiative Forcing")
plt.xlabel("Total Radiative Forcing$\\ \\Delta F_{total} \\, [\\frac{W}{m^2}]$")
plt.ylabel("T [$\\degree C$]")

plt.legend(loc=5)

plt.grid()

plt.show()
plt.close()





sp = st.spearmanr(f_total_c, sea_mean_c)
pe = st.pearsonr(f_total_c, sea_mean_c)


print('Spearman coefficient: %.5f , with pvalue: %.5f' % (sp[0],sp[1]))
print('Pearson coefficient: %.5f , with pvalue: %.5f' % (pe[0],pe[1]))
print("It seems like we may have a monotonic linear correlation, but we cannot be sure with these values for the coefficients")








def sea_linear1(f_total, a, b):
    y = a*f_total + b
    return y


coef_sea1, cova_sea1 = opt.curve_fit(sea_linear1,f_total_c,sea_mean_c)
#Uncertainties
sigma_coef_sea1 = np.sqrt(np.diag(cova_sea1))

print("Best-fit parameters are: \n", coef_sea1)
print("Associate uncertainties: \n", sigma_coef_sea1)
print("The resulting line equation is: y = (%.4f +/- %.4f) * x - (%.4f +/- %.4f)" %(coef_sea1[0], sigma_coef_sea1[0],abs(coef_sea1[1]),sigma_coef_sea1[1]))


sea_linear_fit1 = sea_linear1(f_total_c, *coef_sea1)


plt.figure(figsize=(15,5))

plt.scatter(f_total_c, sea_mean_c, color = "k", label = "Sea Temperature Anomaly")
plt.errorbar(f_total_c, sea_mean_c, yerr = sea_err_c, color = "darkslategray", linestyle = " ", marker = " ",label = "$2\\sigma$ symmetric errors")
plt.plot(f_total_c, sea_linear_fit1, color = "r", label = "Linear Model: \n $\\Delta T_{sea} = %.4f \\, \\Delta F_{total} - %.4f$" %(coef_sea1[0], abs(coef_sea1[1])))

plt.title("Sea Temperature Anomaly  vs Global Radiative Forcing")
plt.xlabel("Total Radiative Forcing$\\ \\Delta F_{total} \\, [\\frac{W}{m^2}]$")
plt.ylabel("T [$\\degree C$]")

plt.legend(loc = "upper left")

plt.grid()

plt.show()
plt.close()


k_slope = 0.29
sigma_k = 0.08


print("The difference between the expected slope and the one from our model is: ", k_slope - coef_sea1[0])








def sea_linear2(f_total, a):
    y = a*f_total 
    return y


coef_sea2, cova_sea2 = opt.curve_fit(sea_linear2,f_total_c,sea_mean_c)
#Uncertainties
sigma_coef_sea2 = np.sqrt(np.diag(cova_sea2))

print("Best-fit parameters are: \n", coef_sea2)
print("Associate uncertainties: \n", sigma_coef_sea2)
print("The resulting line equation is: y = (%.4f +/- %.4f) * x" %(coef_sea2[0], sigma_coef_sea1[0]))


sea_linear_fit2 = sea_linear2(f_total_c,coef_sea2)


plt.figure(figsize=(15,5))

plt.scatter(f_total_c, sea_mean_c, color = "k", label = "Sea Temperature Anomaly")
plt.errorbar(f_total_c, sea_mean_c, yerr = sea_err_c, color = "darkslategray", linestyle = " ", marker = " ",label = "$2\\sigma$ symmetric errors")
plt.plot(f_total_c, sea_linear_fit2, color = "b", label = "Linear Model: \n $\\Delta T_{sea} = %.4f \\, \\Delta F_{total}$" %(coef_sea2[0]))

plt.title("Sea Temperature Anomaly  vs Global Radiative Forcing")
plt.xlabel("Total Radiative Forcing$\\ \\Delta F_{total} \\, [\\frac{W}{m^2}]$")
plt.ylabel("T [$\\degree C$]")

plt.legend(loc = "upper left")

plt.grid()

plt.show()
plt.close()


print("The difference between the expected slope and the one from our second model is: ", k_slope - coef_sea2[0])








# Defining a time array for the future date range
future_date = np.arange(2040, 2110,1)





# Using the model defined in the first part of the homework
coef_sea_f, cova_sea_f = opt.curve_fit(model1, time_range, sea_mean_c)
coef_f_t, cova_f_t = opt.curve_fit(model1, time_range, f_total_c)

# Uncertainties
sigma_coef_sea_f = np.sqrt(np.diag(cova_sea_f))
sigma_coef_f_t = np.sqrt(np.diag(cova_f_t))

# Reporting
print("Best-fit parameters for sea temperature anomaly:", coef_sea_f)

print("Associate uncertainties for sea temperature anomaly:", sigma_coef_sea_f)

print("Best-fit parameters for global radiative forcing:", coef_f_t)

print("Associate uncertainties for global radiative forcing:", sigma_coef_f_t)


# # Just to check, let's see this models in a plot with the known values
# sea_anomaly = model1(time_range, *coef_sea_f) 
# f_global = model1(time_range, *coef_f_t) 
# # Plotting
# fig, (ax1, ax2) = plt.subplots(1,2, figsize = (18,4.5))

# ax1.plot(time_range, sea_anomaly)
# ax1.plot(time_range, sea_mean_c)

# ax2.plot(time_range, f_total_c)
# ax2.plot(time_range, f_global)

# # We can see that it's not that good for the sea anomaly temperature


# Getting the values between our range of interest
sea_future = model1(future_date, *coef_sea_f) 
f_global_future = model1(future_date, *coef_f_t) 

# By propagation of errors
sigma_sea_future = future_date*sigma_coef_sea_f[0]
sigma_f_global_future = future_date*sigma_coef_f_t[0]



fig, (ax1, ax2) = plt.subplots(1,2, figsize = (15,4.5))

ax1.scatter(2050, model1(2050, *coef_f_t), marker = "o", label = "$\\Delta F_{global} $ at 2050")
ax1.scatter(2100, model1(2100, *coef_f_t), marker = "o", label = "$\\Delta F_{global} $ at 2100")
ax1.plot(future_date, f_global_future, color = "k", label = "$ Future \\Delta F_{global}$")
ax1.errorbar(future_date, f_global_future, yerr = sigma_f_global_future, label = "Uncertainties", color = "gray", alpha = 0.4)
ax1.grid()
ax1.legend()

ax2.scatter(2050, model1(2050, *coef_sea_f), marker = "o", label = "Sea Temperature Anomaly at 2050")
ax2.scatter(2100, model1(2100, *coef_sea_f), marker = "o", label = "Sea Temperature Anomaly at 2100")
ax2.plot(future_date, sea_future, color = "b", label = "Future Sea Temperature Anomaly")
ax2.errorbar(future_date, sea_future, yerr = sigma_sea_future, label = "Uncertainties", color = "gray", alpha = 0.4)
ax2.grid()
ax2.legend()

ax1.set_xlabel("time [year]")
ax2.set_xlabel("time [year]")
ax1.set_ylabel("$\\Delta F \\, [\\frac{W}{m^2}]$")
ax2.set_ylabel("T [$\\degree C$]")


plt.tight_layout()
plt.show()








uncertainties_s = np.sqrt((f_global_future*sigma_coef_sea1[0])**2 + (sigma_f_global_future*coef_sea1[0])**2 + (sigma_coef_sea1[1])**2) 


plt.figure(figsize=(15,5))

plt.scatter(f_global_future, sea_future, color = "k", label = "Future Surface Sea Temperature Anomaly from regressions", marker = ".")
plt.scatter(model1(2050, *coef_f_t), model1(2050, *coef_sea_f), marker = "o", s = 100, label = "$\\Delta T_{sea} $ at 2050")
plt.scatter(model1(2100, *coef_f_t), model1(2100, *coef_sea_f), marker = "o", s = 100, label = "$\\Delta T_{sea} $ at 2100")
plt.errorbar(f_global_future, sea_future, yerr = uncertainties_s, color = "darkslategray", linestyle = " ", marker = " ",label = "$\\sigma_{\\Delta T_{sea}}$ from linear relation", alpha = 0.5)
plt.plot(f_global_future, sea_linear1(f_global_future, *coef_sea1), color = "r", label = "Linear Model: \n $\\Delta T_{sea} = %.4f \\, \\Delta F_{total} - %.4f$" %(coef_sea1[0], abs(coef_sea1[1])))

plt.title("Sea Temperature Anomaly  vs Global Radiative Forcing")
plt.xlabel("Total Radiative Forcing$\\ \\Delta F_{total} \\, [\\frac{W}{m^2}]$")
plt.ylabel("T [$\\degree C$]")

plt.legend(loc = "upper left")

plt.grid()

plt.show()
plt.close()


# Getting the actual values for the Sea Surface Temperature Anomaly 
STA_2050 = model1(2050, *coef_sea_f)
STA_2100 = model1(2100, *coef_sea_f)


# Reporting them
print("The surface sea temperature anomaly (Delta T_sea) in 2050 will be: %.4f [°C]" %(STA_2050))
print("The surface sea temperature anomaly (Delta T_sea) in 2100 will be: %.4f [°C]" %(STA_2100))






